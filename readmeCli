shell stuff

Using ctrl^
--------------------------------------------------

a   -   move to ^

e   -   move to $

b   -   move back one char

f   -   move forward one char

w   -   delete previous word

k   -   delete in front of cursor

h   -   delete one char

u   -   delete entire line

y   -   paste last deletion

p   -   paste previous line

s   -   stop output printing (XOFF)

q   -   restart output printing (XON)


stty (key bindings)
--------------------------------------------------

To add different stop characters for ctrl-w:
    Add to .bashrc
        stty werase undef
        bind '\C-w:unix-filename-rubout'
        Source your .bashrc followed by your .profile
    Alternatively, press ESC then backspace to mimic


$$$$$$$$$$$$$$$$$$$$$$$$$$$$
AWK & SED
$$$$$$$$$$$$$$$$$$$$$$$$$$$$

For sed, note that the substitute command can use a variety of delimiters, as long as you're 
consistent. For example, try using s^^^g instead of s///g.

-----------------------------

sed is a stream editor. It works with streams of characters on a per-line basis. It has a 
primitive programming language that includes goto-style loops and simple conditionals (in 
addition to pattern matching and address matching). There are essentially only two 
"variables": pattern space and hold space. Readability of scripts can be difficult.
Mathematical operations are extraordinarily awkward at best.

awk is oriented toward delimited fields on a per-line basis. It has much more robust 
programming constructs including if/else, while, do/while and for (C-style and array 
iteration). There is complete support for variables and single-dimension associative arrays 
plus (IMO) kludgey multi-dimension arrays. Mathematical operations resemble those in C. It has
printf and functions. 

The "K" in "AWK" stands for "Kernighan" as in "Kernighan and Ritchie" of the book "C 
Programming Language" fame (not to forget Aho and Weinberger). One could conceivably write a 
detector of academic plagiarism using awk.

Both programs use regular expressions for selecting and processing text.

I would tend to use sed where there are patterns in the text. For example, you could replace 
all the negative numbers in some text that are in the form "minus-sign followed by a sequence of digits" (e.g. "-231.45") with the "accountant's brackets" form (e.g. "(231.45)") using this
(which has room for improvement):

    sed 's/-\([0-9.]\+\)/(\1)/g' inputfile

I would use awk when the text looks more like rows and columns or, as awk refers to them 
"records" and "fields". If I was going to do a similar operation as above, but only on the 
third field in a simple comma delimited file I might do something like:

    awk -F, 'BEGIN {OFS=","} {gsub("-([0-9.]+)","(&)",$3);print}' inputfile

Of course those are just very simple examples that don't illustrate the full range of 
capabilities that each has to offer.


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

If your shell is Bash (or similar), this set of redirections will do the job:

Code:
$ command 3>&1 1>&2 2>&3 | tee file

What does it mean?

The redirection operator n>&m makes file descriptor n to be a copy of file
descriptor m. So, whe are:
- Opening a new file descriptor, 3, that is a copy of file descriptor 1, the
  standard output;
- Making file descriptor 1 a copy of file descriptor 2, the standard error
  output;
- Making file descriptor 2 to be a copy of file descriptor 3 (the "backup" of
  the standard output)

In short: we swapped the standard output and the standard error output.
